{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "1P1_fynNB6JyMJGEU-4_ZZhF9L-TpeBoC",
      "authorship_tag": "ABX9TyN8tTwOxHDYZsO0scVX/Mqh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SriRamK345/Predicting-DoorDash-ETA-A-Machine-Learning-Approach/blob/main/Predicting_DoorDash_ETA_A_Machine_Learning_Approach.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Summary encapsulates a comprehensive data science workflow applied to predicting DoorDash delivery times.**\n",
        "\n",
        "### **Data Preprocessing**\n",
        "1. **Handling Missing Data**:\n",
        "   - Rows with missing values and duplicates are removed, ensuring data integrity.\n",
        "2. **Feature Engineering**:\n",
        "   - Creation of new features like `delivery_duration_sec` and `free_dashers` to improve model insights and performance.\n",
        "3. **Data Transformation**:\n",
        "   - Conversion of date columns to datetime objects for temporal analysis.\n",
        "   - Removal of unnecessary columns and outliers in the target variable to refine the dataset.\n",
        "\n",
        "### **Exploratory Data Analysis (EDA)**\n",
        "- Visual tools such as:\n",
        "  - **Count plots**: For categorical data distribution.\n",
        "  - **Scatter plots**: To examine relationships between variables.\n",
        "  - **Heatmaps**: For correlation analysis.\n",
        "- These provide insights into variable interactions and distributions.\n",
        "\n",
        "### **Model Building and Evaluation**\n",
        "1. **Data Preparation**:\n",
        "   - Splitting data into training and testing sets.\n",
        "   - Feature scaling with `MinMaxScaler` to standardize the feature range.\n",
        "2. **Model Training**:\n",
        "   - Models used: Linear Regression, Random Forest, XGBoost, and a Neural Network.\n",
        "3. **Model Evaluation**:\n",
        "   - Performance metrics include:\n",
        "     - **R-squared**: Proportion of variance explained.\n",
        "     - **MAE**, **MSE**, and **RMSE**: Indicators of prediction accuracy.\n",
        "\n",
        "### **Model Selection and Deployment**\n",
        "1. **Best Model Selection**:\n",
        "   - The Neural Network outperformed others based on evaluation metrics.\n",
        "2. **Model Saving and Deployment**:\n",
        "   - Saved using `model.save()` for reuse.\n",
        "   - A function enables loading the saved model and predicting new data seamlessly.\n",
        "\n",
        "### **Conclusion**\n",
        "This project effectively follows the data science pipeline:\n",
        "- Data cleaning and transformation ensure robust input.\n",
        "- EDA highlights key insights.\n",
        "- Model building explores various algorithms.\n",
        "- Deployment enables practical use of the Neural Network for accurate delivery time predictions.\n",
        "\n",
        "This structured approach showcases expertise in handling end-to-end machine learning projects and can be applied to similar prediction tasks."
      ],
      "metadata": {
        "id": "xcuF6NOL8USB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Steps to get data sets from kaggle"
      ],
      "metadata": {
        "id": "0S2oZ1TxGJgk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3XFbwj7X2kSN"
      },
      "outputs": [],
      "source": [
        "! mkdir ~/.kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! cp \"/content/drive/MyDrive/kaggle.json\" ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "0M54p3mn2mrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4LTkkP2N853V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download dharun4772/doordash-eta-prediction"
      ],
      "metadata": {
        "id": "Krz4gw9o2muI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip /content/doordash-eta-prediction.zip"
      ],
      "metadata": {
        "id": "XAuENwKo3SE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "Vrjk37pw4BR2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data cleaning\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# Visualization / EDA\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "# remove warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "# Split data for training and testing & Optimizing model parameters\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Model evaluation\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "# Model selection\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "# Feature scaling\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# TenserFlow\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "tdDqE4za3fHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import dataset"
      ],
      "metadata": {
        "id": "0lajcyk-4Lqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df= pd.read_csv(\"/content/historical_data.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "CxJQ3e553Y6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `Feature descriptions`\n",
        "\n",
        "1. **market_id** - A city/region in which DoorDash operates, e.g., Los Angeles, given in the data as an id\n",
        "2. **created_at** - When the order was submitted by the consumer to DoorDash.\n",
        "3. **actual_delivery_time** - When the order was delivered\n",
        "4. **store_id** - Representing the restaurant ID\n",
        "5. **store_primary_category** - cuisine category of the restaurant\n",
        "6. **order_protocol** - a store can receive orders from DoorDash through many modes. This field represents an id denoting the protocol.\n",
        "7. **total_items** - total number of items in the order\n",
        "8. **subtotal** - total value of the order submitted (in cents)\n",
        "9. **num_distinct_items** - number of distinct items included in the order\n",
        "10. **min_item_price** - price of the item with the least cost in the order (in cents)\n",
        "11. **max_item_price** - max price of the item\n",
        "12. **total_onshift_dashers:** The total number of delivery drivers who are currently available and actively working.\n",
        "13. **total_busy_dashers:** The total number of delivery drivers who are currently occupied with delivering orders.\n",
        "14. **total_outstanding_orders:** The total number of orders that have been placed but have not yet been delivered.\n",
        "15. **estimated_order_place_duration:** The estimated time it takes for a customer to place an order.\n",
        "16. **estimated_store_to_consumer_driving_duration:** The estimated time it takes for a delivery driver to travel from the store to the customer's location.\n",
        "\n",
        "The target value to predict here is the total seconds value between created_at and actual_delivery_time.\n"
      ],
      "metadata": {
        "id": "RB2Gptbr5Xv7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploring Data"
      ],
      "metadata": {
        "id": "zOKblrct5KaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "xjnkjZA75y-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check for data types"
      ],
      "metadata": {
        "id": "WsUMQZREHIMg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "HoLp4eGc3d9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "s0eaMsYY4Pbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking Null values\n",
        "\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "6XTAiJnK40Wa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking Null values\n",
        "print(f\"There are {df.isnull().sum().sum()} null values in this dataset\")"
      ],
      "metadata": {
        "id": "t-D587rBDT3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Data Preprocessing"
      ],
      "metadata": {
        "id": "Ez0waD2eHjnw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ratio of missing values"
      ],
      "metadata": {
        "id": "mvXQAVaCEWtf"
      }
    },
    {
      "source": [
        "total_rows = df.shape[0]\n",
        "total_missing_values = df.isnull().sum().sum()\n",
        "\n",
        "if total_missing_values == 0:\n",
        "    print(\"There are no missing values in the DataFrame.\")\n",
        "else:\n",
        "    missing_values_ratio = total_rows / total_missing_values\n",
        "    print(f\"The ratio of total rows to missing values is: {missing_values_ratio:.2f}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "22aCGIzjENQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`The missing values is minimun so we can remove those from the dataset and dropping duplicate values`**"
      ],
      "metadata": {
        "id": "s8aNqdtaEctE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop_duplicates(inplace=True) # to drop duplicate values\n",
        "df.dropna(inplace=True) # to drop null values"
      ],
      "metadata": {
        "id": "RIm7Uua5D6cF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get descriptive statistics to understand the distribution of numerical features\n",
        "df.describe().T"
      ],
      "metadata": {
        "id": "3GgYSgs6E5hM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.describe(include='object'))  # Categorical columns"
      ],
      "metadata": {
        "id": "kzzhaIMFVY7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Convert Date Columns"
      ],
      "metadata": {
        "id": "5ql0ma2gFYCC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['created_at'] = pd.to_datetime(df['created_at'])\n",
        "df['actual_delivery_time'] = pd.to_datetime(df['actual_delivery_time'])"
      ],
      "metadata": {
        "id": "wFb_cYhwE6wT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering"
      ],
      "metadata": {
        "id": "Cta4EdSlH2W1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the delivery duration in seconds by subtracting the order creation time\n",
        "# from the actual delivery time and extracting the total seconds.\n",
        "df['delivery_duration_sec'] = (df['actual_delivery_time'] - df['created_at']).dt.total_seconds()\n",
        "df.head()"
      ],
      "metadata": {
        "id": "zBImfHV8HyZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the number of free dashers\n",
        "df[\"free_dashers\"] = df[\"total_onshift_dashers\"] - df[\"total_busy_dashers\"]\n",
        "df.head()"
      ],
      "metadata": {
        "id": "mBblIubVRfB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference\n",
        "\n",
        "`Could be able to see negative value in free_dashers column, Indicates there is no persons available to pick and deliver the order. Hence there was a delay in delivery.`"
      ],
      "metadata": {
        "id": "JZNzjCfSSQRD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Column Unique Values"
      ],
      "metadata": {
        "id": "-7YWYvZXQHj5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique_number = []\n",
        "for i in df.columns:\n",
        "    x = df[i].value_counts().count()\n",
        "    unique_number.append(x)\n",
        "\n",
        "pd.DataFrame(unique_number, index = df.columns, columns = [\"Total Unique Values\"])"
      ],
      "metadata": {
        "id": "-sjh3mYVQH2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDA"
      ],
      "metadata": {
        "id": "99PclH-fPrPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Marlket Count\n",
        "sns.countplot(x=df[\"market_id\"], palette=\"Set2\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "29XIks-gPvBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=df[\"store_primary_category\"], y=df[\"total_items\"],palette=\"Set2\")\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "URnZvRcrQDoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`All cuisine category of the restaurant were sold well`"
      ],
      "metadata": {
        "id": "Ygo68AceYQTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(x=df[\"total_items\"], y=df[\"delivery_duration_sec\"], palette=\"Set2\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lNvWFoIqUK6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x=df[\"store_id\"], y=df[\"delivery_duration_sec\"], palette=\"railbow\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-8et8IeqZnjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.distplot(np.sqrt(df[\"delivery_duration_sec\"]))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "r1RAlMo1fedc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# heatmap\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(df.select_dtypes(include=np.number).corr(), annot=True, cmap='BrBG',linewidths=0.5)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HjmnFTb7Vgp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Droping Outliers in Target column"
      ],
      "metadata": {
        "id": "82-0ezh55KVq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drop_out= df[df[\"delivery_duration_sec\"] > 10000]\n",
        "print(len(drop_out))\n",
        "\n",
        "df.drop(drop_out.index, inplace=True)"
      ],
      "metadata": {
        "id": "vs-YGZ055Kqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "px.box(df, y=\"delivery_duration_sec\")"
      ],
      "metadata": {
        "id": "0dtjAYoh6nra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Removing Unwanted columns"
      ],
      "metadata": {
        "id": "XLcCjr0absMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_copy = df.copy()"
      ],
      "metadata": {
        "id": "Rr6XAz6uc6V_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_copy.drop(columns=[\"created_at\",\"market_id\", \"store_id\", \"store_primary_category\", \"order_protocol\",\"subtotal\",\"num_distinct_items\", \"actual_delivery_time\",\"min_item_price\",\"max_item_price\"], inplace=True)"
      ],
      "metadata": {
        "id": "uRvDYySQb5XF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr = df_copy.corr()\n",
        "\n",
        "sns.heatmap(corr, annot=True, cmap='coolwarm',linewidths=0.5)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QcR52Y7lessi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Test Split"
      ],
      "metadata": {
        "id": "JEJb5ZrifDjn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "hSYSctOxe7yJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_copy.drop(\"delivery_duration_sec\", axis=1)\n",
        "y = df_copy[\"delivery_duration_sec\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=25)"
      ],
      "metadata": {
        "id": "ybVskyXRfIqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Scaling"
      ],
      "metadata": {
        "id": "yLMXsWgmfYds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scale = MinMaxScaler()\n",
        "\n",
        "X_train_s = scale.fit_transform(X_train)\n",
        "X_test_s = scale.transform(X_test)\n",
        "\n",
        "y_train_s = scale.fit_transform(y_train.values.reshape(-1, 1))\n",
        "y_test_s = scale.transform(y_test.values.reshape(-1, 1))"
      ],
      "metadata": {
        "id": "tihgamX1fYoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pipeline"
      ],
      "metadata": {
        "id": "woZbXRTxkcE8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = Pipeline([\n",
        "    ('scaler', MinMaxScaler()),\n",
        "    ('model', LinearRegression())\n",
        "])"
      ],
      "metadata": {
        "id": "7j4mEjrwkXIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation matrix"
      ],
      "metadata": {
        "id": "NxvJCwBktA-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluation_matrix(actual, pred):\n",
        "  MAE = mean_absolute_error(actual, pred)\n",
        "  MSE = mean_squared_error(actual, pred)\n",
        "  RMSE = np.sqrt(mean_squared_error(actual, pred))\n",
        "  SCORE = r2_score(actual, pred)\n",
        "  return print(\"\\n\",\"r2_score:\",SCORE , \"\\n\",\"MAE:\", MAE, \"\\n\",\"MSE\",MSE, \"\\n\",\"RMSE\", RMSE)"
      ],
      "metadata": {
        "id": "JkKEI7ZFtBD8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Linear Regression"
      ],
      "metadata": {
        "id": "gh5GPrFMk9Pu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "Jw5oH4znkvpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_model_g = LinearRegression()\n",
        "lr_model_g.fit(X_train_s, y_train_s)\n",
        "y_pred_l = lr_model_g.predict(X_test_s)\n",
        "\n",
        "train_score_LRg= lr_model_g.score(X_train_s,y_train_s)\n",
        "test_score_LRg= lr_model_g.score(X_test_s,y_test_s)\n",
        "print(\"Train Score LR\", train_score_LRg)\n",
        "print(\"Test Score LR\", test_score_LRg)\n",
        "evaluation_matrix(y_test_s, y_pred_l)"
      ],
      "metadata": {
        "id": "dScOxRBilkig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. RandomForestRegressor"
      ],
      "metadata": {
        "id": "bPOFMr8xn6ho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RF_model = RandomForestRegressor()\n",
        "RF_model.fit(X_train, y_train)\n",
        "y_pred_r = RF_model.predict(X_test)\n",
        "\n",
        "train_score_RF= RF_model.score(X_train,y_train)\n",
        "test_score_RF= RF_model.score(X_test,y_test)\n",
        "print(\"Train Score RF\", train_score_RF)\n",
        "print(\"Test Score RF\", test_score_RF)"
      ],
      "metadata": {
        "id": "jNUr2NQrn6pn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_matrix(y_test,y_pred_r)"
      ],
      "metadata": {
        "id": "eor0d1mJs7fH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. XGBoost"
      ],
      "metadata": {
        "id": "cuNE2fYVohuS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xg_boost = XGBRegressor()\n",
        "xg_boost.fit(X_train, y_train)\n",
        "y_pred_x = xg_boost.predict(X_test)\n",
        "\n",
        "train_score_xg= xg_boost.score(X_train,y_train)\n",
        "test_score_xg= xg_boost.score(X_test,y_test)\n",
        "print(\"Train Score XGB\", train_score_xg)\n",
        "print(\"Test Score XGB\", test_score_xg)"
      ],
      "metadata": {
        "id": "KCfB2gpkoqlo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_matrix(y_test,y_pred_x)"
      ],
      "metadata": {
        "id": "IglTCJZwcV9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deep learning Model"
      ],
      "metadata": {
        "id": "mdhlzYy0uSJU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(input_shape):\n",
        "    model = keras.Sequential([\n",
        "        layers.Dense(30, activation=\"relu\", input_shape=input_shape),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(15, activation=\"relu\"),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(1)  # Output layer with 1 neuron for regression\n",
        "    ])\n",
        "    optimizer = tf.keras.optimizers.Adam(0.001) # optimizer\n",
        "\n",
        "    model.compile(loss=\"mean_squared_error\",\n",
        "                  optimizer=optimizer,\n",
        "                  metrics=[\"mae\", \"mse\"])\n",
        "    return model"
      ],
      "metadata": {
        "id": "WSnYj8lOOYYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = X_train_s.shape[1:]  # Input shape for the model\n",
        "\n",
        "nn_model = build_model(input_shape) # Call function\n",
        "\n",
        "# Define the EarlyStopping callback\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor=\"val_loss\",  # Metric to monitor\n",
        "    patience=4,          # Number of epochs to wait before stopping\n",
        "    restore_best_weights=True  # Restore the best model weights\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history = nn_model.fit(X_train_s,\n",
        "                           y_train_s,\n",
        "                           epochs=1000,\n",
        "                           validation_split=0.2, verbose=1,\n",
        "                           callbacks=[early_stopping],\n",
        "                           batch_size = 15)"
      ],
      "metadata": {
        "id": "cMRSnzB6Ohon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate the NN model"
      ],
      "metadata": {
        "id": "_ZmNCxZduhMi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, mae, mse= nn_model.evaluate(X_test_s, y_test_s, verbose=0)\n",
        "print(\"Testing set Mean Abs Error: {:.3f} \".format(mae))\n",
        "print(\"Testing set Mean Squared Error: {:.3f}\".format(mse))\n",
        "print(\"Testing set Root Mean Squared Error: {:.3f}\".format(np.sqrt(mse)))"
      ],
      "metadata": {
        "id": "oDW1Cn8jQqzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = nn_model.predict(X_test_s)\n",
        "evaluation_matrix(y_test_s, y_pred)"
      ],
      "metadata": {
        "id": "jKTCrszJQtYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training & validation accuracy values\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['mae'])\n",
        "plt.plot(history.history['val_mae'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('mae')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Da0JaB8sQ-8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving the Neural network model"
      ],
      "metadata": {
        "id": "gnU3s5DBvmT6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nn_model.save('model.keras')"
      ],
      "metadata": {
        "id": "K4ibbPDwRqEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the saved model and prediction"
      ],
      "metadata": {
        "id": "IsCUh_d4vv-Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Model = tf.keras.models.load_model('model.keras')"
      ],
      "metadata": {
        "id": "GqNr4WqavwLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_items = int(input(\"Enter total_items: \"))\n",
        "total_onshift_dashers = int(input(\"Enter total_onshift_dashers: \"))\n",
        "total_busy_dashers = int(input(\"Enter total_busy_dashers: \"))\n",
        "total_outstanding_orders = int(input(\"Enter total_outstanding_orders: \"))\n",
        "estimated_order_place_duration = int(input(\"Enter estimated_order_place_duration: \"))\n",
        "estimated_store_to_consumer_driving_duration = int(input(\"Enter estimated_store_to_consumer_driving_duration: \"))\n",
        "free_dashers = int(input(\"Enter free_dashers: \"))"
      ],
      "metadata": {
        "id": "XSdx6EoJv3Tp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = np.array([[total_items, total_onshift_dashers, total_busy_dashers, total_outstanding_orders, estimated_order_place_duration, estimated_store_to_consumer_driving_duration, free_dashers]])"
      ],
      "metadata": {
        "id": "AYVHHgTvwVkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction(*input_data):\n",
        "  input_data = np.array([input_data])\n",
        "  prediction = Model.predict(input_data)\n",
        "  delivery_duration_sec = scale.inverse_transform(prediction)\n",
        "  return abs(delivery_duration_sec[0][0])\n",
        "\n",
        "print(\"Total seconds to deliver\",prediction(total_items, total_onshift_dashers, total_busy_dashers, total_outstanding_orders, estimated_order_place_duration, estimated_store_to_consumer_driving_duration, free_dashers),\"sec\")"
      ],
      "metadata": {
        "id": "ZEk5Tx_5zJFF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}